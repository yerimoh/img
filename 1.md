7 Limitations
While our approach enables LMs to learn how to
use a variety of tools in a self-supervised way, there
are some clear limitations to what can be achieved
with our method in its current form. One such limitation is the inability of Toolformer to use tools in a
chain (i.e., using the output of one tool as an input
for another tool). This is due to the fact that API
calls for each tool are generated independently; as a
consequence, there are no examples of chained tool
use in the finetuning dataset. Our current approach
also does not allow the LM to use a tool in an interactive way – especially for tools such as search
engines, that could potentially return hundreds of
different results, enabling a LM to browse through
these results or to refine its search query in a similar spirit to Nakano et al. (2021) can be crucial for
certain applications. Beyond this, we found models
trained with Toolformer to often be sensitive to the
exact wording of their input when deciding whether
or not to call an API; this is perhaps unsurprising
given that LMs are known to be very sensitive to
the prompt they are provided with in both zeroand few-shot settings (Jiang et al., 2020; Schick
and Schütze, 2021a). Depending on the tool, our
method is also very sample-inefficient; for example,
processing more than a million documents results
in only a few thousand examples of useful calls
to the calculator API. A potential solution to this
problem might be to iteratively apply our approach,
similar to how this is done in related bootstrapping
approaches (Schick and Schütze, 2021a; Izacard
and Grave, 2021; Parisi et al., 2022). Finally, when
deciding whether or not to make an API call, Toolformer currently does not take into account the
tool-dependent, computational cost incurred from
making an API call.
