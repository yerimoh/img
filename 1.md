Sampling API Calls 

For each API, we write a
prompt P(x) that encourages the LM to annotate an example x = x1, . . . , xn with API calls.
An example of such a prompt for a question answering tool is shown in Figure 3; all prompts
used are shown in Appendix A.2. Let pM(zn+1 |
z1, . . . , zn) be the probability that M assigns to
token zn+1 as a continuation for the sequence
z1, . . . , zn. We first sample up to k candidate positions for doing API calls by computing, for each
i ∈ {1, . . . , n}, the probability


that M assigns to starting an API call at position
i. Given a sampling threshold τs, we keep all positions I = {i | pi > τs}; if there are more than k
such positions, we only keep the top k.
For each position i ∈ I, we then obtain up to m
API calls c
1
i
, . . . , cm
i
by sampling from M given the
sequence [P(x), x1, . . . , xi−1, <API>] as a prefix
and </API> as an end-of-sequence token.2


Executing API 

Calls As a next step, we execute
all API calls generated by M to obtain the corresponding results. How this is done depends entirely
on the API itself – for example, it can involve calling another neural network, executing a Python
script or using a retrieval system to perform search
over a large corpus. The response for each API call
ci needs to be a single text sequence ri





Filtering API Calls 

Let i be the position of the
API call ci
in the sequence x = x1, . . . , xn, and let
ri be the response from the API. Further, given a
sequence (wi
| i ∈ N) of weights, let



be the weighted cross entropy loss for M over the
tokens xi
, . . . , xn if the model is prefixed with z.
We compare two different instantiations of this loss:


where ε denotes an empty sequence. The former is
the weighted loss over all tokens xi
, . . . , xn if the
API call and its result are given to M as a prefix;3
the latter is the minimum of the losses obtained
from (i) doing no API call at all and (ii) doing an
API call, but not providing the response. Intuitively,
an API call is helpful to M if providing it with both
the input and the output of this call makes it easier
for the model to predict future tokens, compared to
not receiving the API call at all, or receiving only
its input. Given a filtering threshold τf , we thus
only keep API calls for which



holds, i.e., adding the API call and its result reduces
the loss by at least τf , compared to not doing any
API call or obtaining no result from it.


