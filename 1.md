Consider one’s own thought process when solving a complicated reasoning task such as a multi-step
math word problem. It is typical to decompose the problem into intermediate steps and solve each
before giving the final answer: “After Jane gives 2 flowers to her mom she has 10 . . . then after she
gives 3 to her dad she will have 7 . . . so the answer is 7.” The goal of this paper is to endow language
models with the ability to generate a similar chain of thought—a coherent series of intermediate
reasoning steps that lead to the final answer for a problem. We will show that sufficiently large
language models can generate chains of thought if demonstrations of chain-of-thought reasoning are
provided in the exemplars for few-shot prompting.



Figure 1 shows an example of a model producing a chain of thought to solve a math word problem
that it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution
and can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it
mimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations
typically come after the final answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,
2022, inter alia)).


Chain-of-thought prompting has several attractive properties as an approach for facilitating reasoning
in language models.


1. First, chain of thought, in principle, allows models to decompose multi-step problems into
intermediate steps, which means that additional computation can be allocated to problems
that require more reasoning steps.


3. Second, a chain of thought provides an interpretable window into the behavior of the model,
suggesting how it might have arrived at a particular answer and providing opportunities
to debug where the reasoning path went wrong (although fully characterizing a model’s
computations that support an answer remains an open question).


5. Third, chain-of-thought reasoning can be used for tasks such as math word problems,
commonsense reasoning, and symbolic manipulation, and is potentially applicable (at least
in principle) to any task that humans can solve via language.


7. Finally, chain-of-thought reasoning can be readily elicited in sufficiently large off-the-shelf
language models simply by including examples of chain of thought sequences into the
exemplars of few-shot prompting.



In empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic
reasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).

