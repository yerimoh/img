11 Conclusion


This paper explores training a lightweight and versatile prompt retriever to improve the zero-shot performance of LLMs. We investigate the retrieverâ€™s
ability to generalize from the trained task types to
unseen task types, and from a small LLM to different LLMs of much larger scales. We hope our paper
will spur further research on developing a universal
assistant for the ever-expanding landscape of tasks
and large language models.


Limitations


While UPRISE has shown consistent performance
gains on most testing clusters, it displays limited
impacts on tasks that are directly formulated as
language modeling, such as Coreference Resolution and Commonsense Reasoning. Future work
may explore including other formats of demonstrations such as chain-of-thought (Wei et al., 2022b)
to improve the performance.
Besides, the universality of UPRISE has been
verified on language only in our experiment, future
work may explore the versatility of UPRISE by incorporating prompts such as tool-use APIs (Schick
et al., 2023), and multimodal information (Huang
et al., 2023; Zhang et al., 2023).

