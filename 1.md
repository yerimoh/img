3.2 RALM Design Choices

We detail below two practical design choices often
made in RALM systems. In §5, we investigate the
effect of these in the setting of In-Context RALM.

Retrieval Stride

While in the above formulation a retrieval operation can occur at each
generation step, we might want to perform retrieval only once every s > 1 tokens due to the
cost of calling the retriever, and the need to replace
the documents in the LM prefix during generation.
We refer to s as the retrieval stride. This gives rise
to the following In-Context RALM formulation
(which reduces back to Eq. (2) for s = 1):

where ns = n/s is the number of retrieval strides.


Notably, in this framework the runtime costs
of each retrieval operation is composed of (a)
applying the retriever itself, and (b) recomputing
the embeddings of the prefix. In §5.2 we show
that using smaller retrieval strides, i.e., retrieving
as often as possible, is superior to using larger
ones (though In-Context RALM with larger strides
already provides large gains over vanilla LM).
Thus, choosing the retrieval stride is ultimately a
tradeoff between runtime and performance.


Retrieval Query Length

While the retrieval
query above in principle depends on all prefix
tokens x≤s·j , the information at the very end
of the prefix is typically the most relevant to
the generated tokens. If the retrieval query is
too long then this information can be diluted.
To avoid this, we restrict the retrieval query at
stride j to the last  tokens of the prefix, i.e.,
we use q
s,
j := xs·j−+1,...,xs·j . We refer to
 as the retrieval query length. Note that prior
RALM work couples the retrieval stride s and the
retrieval query length  (Borgeaud et al., 2022).
In §5, we show that enforcing s =  degrades LM
performance. Integrating these hyper-parameters
into the In-Context RALM formulation gives



