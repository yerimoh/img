Recent works have developed neural models for
various NLP tasks based on tabular data, viz, tabular natural language inference (Orihuela et al.,
2021; Minhas et al., 2022), QA over one or a corpus of tables (Herzig et al., 2020; Yin et al., 2020;
Arik and Pfister, 2021; Glass et al., 2021; Pan et al.,
2021; Chemmengath et al., 2021), table orientation
classification (Habibi et al., 2020; Nishida et al.,
2017), and relation extraction from tables (Govindaraju et al., 2013; Macdonald and Barbosa, 2020).
Several recent papers study QA models—they all
linearize a table and pass it to a pre-trained language model. For example, TAPAS (Herzig et al.,
2020) does this for Wikipedia tables to answer natural language questions by selecting table cells
and aggregation operators. TABERT (Yin et al.,
2020) and RCI (Glass et al., 2021) also use similar
ideas alongside some architectural modifications
to handle rows and columns better. TABBIE (Iida
et al., 2021) consists of two transformers that encode rows and columns independently, whereas
TAPEX uses encoder-decoder architecture using
BART. TABBIE and TAPEX also introduce pretraining over tables to learn table representations
better. Similar to our work, tables have also been
modeled as graphs for sequential question answering over tables (Müller et al., 2019). However, all
these works generally assume a fixed and known
structure of tables with the same orientation, with
the top row being the header row in all cases – an
assumption violated in our setting.





Orientation and semantic structure classification: DeepTable (Habibi et al., 2020) is a
permutation-invariant neural model, which classifies tables into three orientations, while TabNet
(Nishida et al., 2017) uses RNNs and CNNs in a
hybrid fashion to classify web tables into five different types of orientations. INFOTABS (Gupta
et al., 2020) studies natural language inference on
tabular data via linearization and language models,
which has been extended to the multilingual setting (Minhas et al., 2022), and has been combined
with knowledge graphs (Varun et al., 2022). Some
earlier works also focused on annotating column
types, entity ID cells, and pair of columns with
binary relations, based on rule-based and other ML
approaches, given a catalog (Limaye et al., 2010).




