The core of our LLM cascade is the decision maker, which takes in the output from the weaker
LLM, and then decides whether to route to the stronger LLM or not. An ideal cascade decision
maker should call the stronger LLM only when the answer by the weaker LLM is wrong, such that
the total cost C can be minimized without degrading the overall task performance (compared with
using the stronger LLM all the time). To this end, we propose two methodologies based on the
“answer consistency” of the weaker LLM, which we elaborate on below.


Answer Consistency and Sources of Sampling Answer consistency has been found helpful for
improving the LLM performance in reasoning tasks (Wang et al., 2023). Instead of greedily decoding one answer for each question, Wang et al. (2023) sampled a diverse set of reasoning paths
(or thought processes) and then selected the most consistent answer by marginalizing out the sampled paths. Drawing inspiration from the prior work, we make the following hypothesis: When the
weaker LLM samples highly consistent answers for a given question, it reveals a high “confidence”
in solving this question and its most consistent answer is likely to be correct; in this case, there is
thus no need to invoke the stronger LLM.


To realize this intuition, we generalize from Wang et al. (2023) and consider three sources of sampling consistency:


• In-distribution sampling: As Wang et al. (2023), we consider sampling multiple answers given
the same prompt input to the weaker LLM. In practice, this can be achieved by setting a non-zero temperature for the weaker LLM.

• Sampling from different in-context demonstrations: We further consider sampling answers
from two sets of task demonstrations under the same thought representation. For example, to
demonstrate the CoT process in mathematical reasoning tasks, Wei et al. (2022) annotated eight
math examples as the demonstrations and performed 8-shot in-context learning. We additionally
annotated another eight examples as the second set of demonstrations, which allowed us to further
diversify the sources of answer sampling


Sampling from different thought representations: While existing literature typically investigated either CoT or PoT independently, in this work, we propose to leverage the synergy of both
thought representations in a single task. We hypothesize that an LLM obtains truly high confidence in its problem-solving, only when it is able to produce a consistent answer agnostic to how
the intermediate steps are represented. Therefore, we propose to sample the weaker LLM answers
from a “mixture of thought (MoT) representations”, which includes both CoT and PoT prompts.



Below, we introduce our methodologies for consistency checking based on the answer samples.




Method 1: Vote-based decision-making 

The first method calculates the consistency of the
weaker LLM’s answer samples by voting. Formally, for a single prompt, we denote the set
of answers produced by the weaker LLM for each question Q as (Aw
1
, Aw
2
, ..., Aw
K), where K
is the pre-defined number of samples. When sampling from two different prompts, we denote
(Aw
11, Aw
12, ..., Aw
1K1
) and (Aw
21, Aw
22, ..., Aw
2K2
) as the answer samples produced by each of them,
where K1 and K2 represent the pre-defined sample size for each prompt setting, respectively. Note
that for this method, we do not distinguish answers sampled with a single prompt or multiple prompts
(e.g., samples from different prompts have exactly equal weights when voting). The most consistent answer can then be selected as the one that most samples agree with, and this answer will also
be regarded as the final answer Aw by the weaker LLM. The decision maker measures the weaker
LLM’s consistency via the agreement score
The larger the s, the more consistent the weaker LLM’s answer samples. In conjunction with a
pre-defined threshold value τ , the decision maker accepts the weaker LLM’s most consistent answer
Aw when s ≥ τ and rejects it otherwise. As a result, the total cost of answering a question (Eq 1)
can vary depending on the threshold.




Method 2: Verification-based decision-making 

In the case of producing samples from two different prompt settings (i.e., different demonstrations or thought representations), we propose the
second method, which compares the most consistent answers produced by each prompt as the answer verification. As previously mentioned, we could obtain two sets of answers from distinct
prompts: (Aw
11, Aw
12, ..., Aw
1K1
) and (Aw
21, Aw
22, ..., Aw
2K2
). Our method then verifies the most consistent answers within each prompt, denoted as Aw′
1
and Aw′
2
respectively, as follows:


Only when s equals 1, i.e., when the two answers are the same, the weaker LLM’s answer will be
accepted by the decision maker. In this case, the final answer of the weaker LLM will be the same
as the two most consistent answers, i.e., Aw = Aw′
1 = Aw′
2
.



In comparison, these two methods have different applicable scenarios. The vote-based method is
well-suited for scenarios with pre-defined cost constraints. In such cases, we have the flexibility to
tune the threshold to ensure it aligns with the constraint. On the other hand, the verification-based
method is capable of producing relatively optimal results without the need for threshold tuning,
although it lacks flexibility. We will systematically compare the two methods in experiments.

