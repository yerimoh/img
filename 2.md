3 Supervised Morpheme Segmentation



Recent work evaluating morphological segmentation at scale such as the SIGMORPHON 2022
Shared Task (Batsuren et al., 2022) demonstrates
the impressive performance of supervised methods compared to unsupervised methods like BPE
(Gage, 1994) or Morfessor (Creutz et al., 2005),
even for languages with more limited annotated
data than English. In the SIGMORPHON 2022
Shared Task, the organizers compile a large quantity of segmented morpheme data, over half a million English words obtained from Wiktionary and
other sources using both hand-crafted and automated methods (Batsuren et al., 2021).



3.1 Evaluating Biomedical Segmentation

By comparing the SIGMORPHON dataset with
words which appear frequently in the Unified
Medical Language System (UMLS) (Bodenreider,
2004), a large scale biomedical knowledge base,
we find that a small percentage (approximately
10%) of all annotated words are relevant biomedical terms. We therefore leverage this biomedical
subset to evaluate the biomedical morpheme segmentation performance of several current tokenization methods. Due to the large difference in scale of
the full dataset to the biomedical subset, we use the
full SIGMORPHON dataset for training, including
both general english and biomedical words. We
use the same segmentation F1 score the SIGMORPHON Shared Task for evaluation. This score is
calculated as the harmonic mean of precision, the
ratio of correctly predicted morphemes over all predicted morphemes, and recall, the ratio of correctly
predicted morphemes over all gold-label units. For
more information about these evaluation metrics,
we refer the interested reader to Section 2.3 of Batsuren et al. (2022).



As seen in Table 3, both BERT and PubMedBERT achieve under 20% segmentation F1 performance on the SIGMORPHON biomedical development subset. In order to understand why current tokenizers obtain such dramatically low segmentation
accuracy, we analyze 50 instances of sub-optimal
tokenization. Apart from words which are not segmented because they exist in the PubMedBERT
vocabulary, most errors are split into three main
categories 1) missing units, 2) compound units and
3) ambiguous connecting vowels. Table 4 shows
descriptions and examples of each type.



3.2 CANINE Fine-Tuning


As opposed to sub-word tokenization, morpheme
segmentation does not require sub-word compo
nents (morphemes) to map directly onto a word’s
characters. For instance, in Table 5, SIGMORPHON annotations transform the root ‘neur’ into
the word ‘neuron’, introducing further flexibility
and complexity to the task. In order to adapt morpheme segmentation annotations to standard tokenization, we design rule-based heuristics that map
each morpheme onto a subset of characters in the
original word. Due to this new formulation and
the success of transformer based models on this
shared task, we choose a character based language
model named CANINE (Clark et al., 2022) as the
model to train for character tagging as morpheme
segmentation. More formally, the segmentation
task is re-framed as classifying each character into
a B(egin) or I(nside) tag, where the B tag indicates
the start of a new morpheme or token
After fine-tuning CANINE on the full SIGMORPHON 2022 training set to create a supervised tokenization system, as seen in Figure 1 (left), we
find that it achieves a 74% segmentation F1 score
on the biomedical SIGMORPHON subset, a very
strong result compared to current tokenizers. For
reference, the best segmentation F1 score reported
in the English word-level test set of the SIGMORPHON 2022 Shared Task is 93.7% by the DeepSpin
team (Peters and Martins, 2022). Even though this
score is not comparable to ours due to our use of a
biomedical development subset for evaluation, we
note that our fine-tuned CANINE model’s perfor
mance is quite strong given that it is designed for
pure tokenization as explained above.
