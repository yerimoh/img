Word Clustering. To achieve good performance, many
machine learning techniques that are used in natural language
processing must first be trained in a supervised fashion by
providing a large collection of text from the target domain that
has been manually annotated with the desired results. However,
previous work has shown that the performance of these
methods can be improved by adding unsupervised word
representations as extra word features.21 This is particularly
useful in the chemistry domain, where the relative lack of
annotated text collections for supervised training can be
compensated for by using word cluster features derived from
the extensive and widely available unannotated literature.
Our system makes use of features derived from Brown
clustering,22 a form of hierarchical clustering of words based on
the contexts in which they occur. This has been shown to
improve the performance of part-of-speech tagging and named
entity recognition in a variety of domains.21,23âˆ’26 Figure 3
shows how various components of our natural language
processing pipeline incorporate both unsupervised and
supervised learning.
Clustering was performed on the full text and captions of
3592 chemistry articles published by the ACS, RSC, and
Springer. Once tokenized, this collection consists of about 20
million words in about 700 000 sentences. Clustering was
performed using the Liang C++ implementation27 to produce
1500 clusters containing 372 799 unique words. Figure 4 shows
the highest frequency words in seven example clusters. As
Brown clusters are hierarchical, different length prefixes of the
binary path correspond to cluster supersets, which can also be
used as features in machine learning methods.
