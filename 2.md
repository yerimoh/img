Prior works have suggested that pre-trained language models possess limited understanding of
commonsense knowledge (Merrill et al., 2021; Talmor et al., 2021; Davis and Marcus, 2017) despite otherwise stellar performance on leaderboards. As
a result, symbolic commonsense knowledge graphs
(Speer et al., 2017; Sap et al., 2019; Hwang et al.,
2021) and corresponding neural representations
(Bosselut et al., 2019; Hwang et al., 2021; Zhang
et al., 2020b) have supplemented past models with
commonsense capabilities. This has enabled diverse downstream applications, including interactive learning through a conversational interface
(Arabshahi et al., 2021), persona- and affect-aware
conversation models (Kearns et al., 2020), figurative language understanding (Chakrabarty et al.,
2020, 2021), story telling (Ammanabrolu et al.,
2021a) and fantasy games (Ammanabrolu et al.,
2021b).




The common practice for commonsense knowledge graph construction sees humans spell out
as many pieces of knowledge as possible. This
pipeline goes from–human–to–corpus–to–machine,
with commonsense models trained from human authored knowledge graphs. Yet, high-quality,
human-authored knowledge is expensive to scale,
limiting coverage; this motivates an alternative:
from–machine–to–corpus–to–machine. Prior efforts toward automatic commonsense knowledge
graphs have resulted in considerably lower quality than human-written data (Hwang et al., 2021;
Zhang et al., 2020b), which in turn leads to less
reliable neural models (Hwang et al., 2021). Broad
literature consistently shows machine-authored
knowledge graphs underperform human-authored
graphs (Etzioni et al., 2011; Mitchell et al., 2015;
Bollacker et al., 2008).




In this work, we propose Symbolic knowledge
distillation, a new conceptual framework towards
high-quality automatic knowledge graphs for commonsense, leveraging state-of-the-art models and
novel methodology. Most prior art for automatic
knowledge graph construction extracts knowledge
from raw text (Bhakthavatsalam et al., 2020; Zhang
et al., 2020a; Zhou et al., 2020; Zhang et al., 2020b;
Li et al., 2020). In contrast, our approach is motivated by knowledge distillation (Hinton et al.,
2015) wherein a larger teacher model transfers
knowledge to a compact student model (§2.1). Our
method differs from prior knowledge distillation in
key ways: we distill a symbolic knowledge graph
(i.e., generated text) in addition to a neural model,
and we distill only a selective aspect of the teacher
model. This selectively allows the student model
to be of a different type (commonsense model),
compared to the teacher (general language model),
enriching the scope of distillation. An added benefit is that knowledge distilled as text is human
readable: it can be understood and evaluated.







A general language model–GPT-3 in our case–is
an imperfect commonsense teacher on its own, and
the ability to evaluate distilled knowledge is useful
in improving it. We empirically demonstrate that,
by training a separate critic model to judge symbolic generation quality, a more precise teacher can
be defined. Knowledge from this critical teacher
is higher quality–even exceeding human-authored
knowledge. Yet even before training a critic, our
study makes the unexpected finding that the student
model surpasses the commonsense of GPT-3, our
knowledge source.



To test symbolic knowledge distillation against
the human–to–corpus–to–machine paradigm, we
compare with ATOMIC20
20 (Hwang et al., 2021),
which is a human-authored commonsense knowledge graph. We find that ATOMIC10x, our machinegenerated corpus, exceeds the human generated
corpus in scale, accuracy, and diversity with respect to 7 commonsense inference types that we
focus on in this study. The resulting commonsense
model, COMETDIS
TIL, not only surpasses the humantrained equivalent COMET20
20, but is also smaller,
more efficient, and produces commonsense at a
higher accuracy than its own teacher–GPT-3.


Symbolic knowledge distillation offers a promising new role for general language models, as commonsense knowledge sources, and humans, as
small-scale evaluators to train critic models rather
than authors of commonsense knowledge. Our
work demonstrates that humans and LMs can be
effective collaborators for curating commonsense
knowledge graphs and training efficient and performant commonsense models.


