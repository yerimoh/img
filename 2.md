Throughout our work, we describe the machine–
to–corpus–to–machine methodology of symbolic
knowledge distillation. We first go machine–to–
corpus (§3), by decoding from GPT-3, then improve our knowledge with a specialized critic
model (§4), and finally distill this knowledge
into an efficient commonsense model (§5), going
corpus–to–machine. Throughout this process, we
evaluate against a human knowledge source, comparing our automatic knowledge graph ATOMIC10x
and commonsense model COMETDIS
TIL to the humanauthored ATOMIC20
20 and resulting model COMET20
20
(Hwang et al., 2021).




2.1 Symbolic Knowledge Distillation



Our proposed methodology parallels knowledge
distillation (Hinton et al., 2015), a method for compressing a large or complicated teacher distribution
Pt
into a smaller/simpler student distribution Ps.
Key to knowledge distillation2
is the notion of minimizing the cross-entropy between Pt and Ps:





Knowledge is transferred to the student by encouraging it to match teacher predictions. Hinton et al.
(2015) apply this to conditional classification: for
each training input, Pt and Ps are model predictions over label set Y . Typically Y is a tractable set,
over which this sum can reasonably be calculated.



For distilling the knowledge of generative models, we can think of an unconditional language
model (LM e.g. GPT-3) as Pt
. This makes Y the
set of all strings, over which LMs define probability.
Unfortunately Y is an exponential set, intractable
to sum over in Eq 1. Kim and Rush (2016) address
this problem by simply taking the mode of Pt over
Y , truncating most of the teacher distribution to the
most likely sequence and discarding information.




Instead, we consider a sampling-based interpretation of the same objective:
which exactly equals the cross-entropy of Eq 1, at
the limit under pure sampling from Pt
.
3




Yet distilling all knowledge from the teacher may
not be desirable–our work is specifically focused
on distlling commonsense knowledge from GPT3. The ideal teacher Pt
is a commonsense expert,
but GPT-3 can approximate such a teacher, off-theshelf, via prompting. This ability to select information is one explicit benefit of the sampling-based
interpretation of Eq 2: while Eq 1 uses continuous logits over existing data, sampling gives discrete control over transferred information, by selecting which samples are elicited and used. For
the general language model GPT-3, We encourage domain/quality with prompting, and sample
truncation (Holtzman et al., 2020). We call this
the loose teacher P
L
t –knowledge is generated and
transferred from GPT-3, but without critical assessment of correctness (§3).


In fact, sampling knowledge in Eq 2 offers even
more control, as generations can be individually
interpreted and judged. Given an indicator function
A(x) for which knowledge x is correct, we can
define a stronger teacher model. Using a Product of
Experts (Hinton, 2002) between the loose teacher
P
L
t
and and the critic A(x), we define a critical
teacher:




In practice, A(x) is a textual classifier learned on
human judgements, 1 for knowledge predicted to
be correct and 0 otherwise. Thus, the critic gives
control over the correctness and confidence of the
knowledge that is transferred (§4).



