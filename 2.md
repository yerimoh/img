We present NOVACOMET, an open commonsense knowledge model, that combines the
best aspects of knowledge models and general
task models. Compared to previous knowledge
models, NOVACOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models
like Flan-T5, NOVACOMET explicitly centers
knowledge, enabling superior performance for
commonsense reasoning.


NOVACOMET leverages the knowledge of
opaque proprietary models to create an open
knowledge pipeline. First, knowledge is symbolically distilled into NOVATOMIC, a publiclyreleased1 discrete knowledge graph which can
be audited, critiqued, and filtered. Next, we
train NOVACOMET on NOVATOMIC by finetuning an open-source pretrained model. NOVACOMET uses an open-format training objective, replacing the fixed relation sets of past
knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs


The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like FlanT5 on a range of commonsense generation
tasks. NOVACOMET serves as a counterexample to the contemporary focus on instruction
tuning only, demonstrating a distinct advantage
to explicitly modeling commonsense knowledge as well
