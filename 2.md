1. Learning symbolic knowledge from language
models can be framed as a symbolic extension
to knowledge distillation. In §2.1, we describe
learning commonsense as a symbolic extension to
knowledge distillation, with GPT-3 a knowledge
source. We elaborate on this process with positive
results in §3,4, and 5.
2. Symbolic knowledge distillation constructs
a high quality knowledge graph at scale. Our
method naturally yields a machine-generated commonsense knowledge graph, which can achieve
impressive quality (§4), beyond that of humanauthored data. An effective critic which filters
incorrect generated knowledge is key.
3. A critical teacher results in a higher quality
student. In §4, we show that making the teacher
more critical results in higher quality knowledge,
even as it reduces the scale of knowledge transferred. This demonstrates that quality matters, not
just quantity, as higher quality knowledge results in
a higher quality commonsense model in §5 despite
smaller scale data.
4. Critical teacher or not, a student can outperform the knowledge source. In §5, we show the
unexpected result that all student models exceed
the quality of GPT-3, the knowledge source.
5. Machines can win over humans for automatic
knowledge graph construction. In §4 and §5,
we show that machine generated knowledge and the
resulting commonsense model can outperform their
equivalents that use a human knowledge source.
Our symbolic knowledge exceeds humans at scale,
quality, and diversity. The resulting commonsense
model achieves the most accurate commonsense
KG completions
