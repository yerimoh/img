We present NOVACOMET, an open commonsense
knowledge model combining the advantages of
both knowledge models and general task models.
NOVACOMET models commonsense knowledge
with an open format, allowing it to be applied
to general reasoning tasks in contrast to previous
knowledge models. Compared to simply training
models to be open task solvers (e.g. instruction tuning) we find that explicitly modeling knowledge in
NOVACOMET also provides a distinct advantage,
with NOVACOMET showing similar or superior
performance to comparable open task models on a
range of commonsense reasoning benchmarks



For NOVACOMET, we leverage opaque, proprietary models like ChatGPT or GPT-4 (Ouyang
et al., 2022; OpenAI, 2023) as the knowledge
source in an open commonsense pipeline (Figure 1).
Such models have demonstrated remarkable commonsense ability (Bubeck et al., 2023; Bian et al.,
2023) yet, closed and opaque, their direct usefulness for studying commonsense is limited. Without
information about training or direct access to the
model, it is impossible to study where reported
gains come from—e.g. the extent of test set contamination with benchmarks.


In our work, we use these models first to generate an open knowledge base (NOVATOMIC, §2.1),
which can be analyzed, improved, and verified
against test set contamination. Next, we train an
open commonsense model (NOVACOMET, §2.3)
on this knowledge: the underlying data and code
will be released along with the model for the study
of commonsense. This allows future testing of
NOVACOMET (and of other models based on NOVATOMIC) to analyze the training set—essentially
allowing us to distill information from a base LLM
into an auditable format.



In training NOVACOMET, we also use an open
format: compared to previous knowledge models
which use a fixed relation set and training order
(head + relation→ tail) we use natural language
queries as relations, and allow masked generation
of all aspects of the data. This allows our model
to be used in a wide range of general reasoning
tasks, thus addressing a significant limitation of
prior knowledge models that are limited to downstream applications capable of effectively leveraging their restricted set of relations. Enabling an
open format also allows the knowledge generation
to focus on pertinent aspects of the context, rather
than forcing the generation of inferences for arbitrary, potentially irrelevant relations Following past work on symbolic knowledge
distillation (West et al., 2022), we also use NOVATOMIC as the basis for training a plausibility
model with human annotations (§2.2), and study
how this can improve NOVACOMET (§2.3).




We test NOVACOMET on a range of commonsense generation tasks, and find that it consistently
outperforms general task models of comparable
size, such as Flan-T5xxl (Chung et al., 2022a) and
T0 on commonsense tasks like abductive infilling
and explanation generation. Furthermore, we assess the ability of our plausibility model to handle
general commonsense QA tasks and observe that
it achieves comparable or superior discriminative
performance on a range of tasks. NOVACOMET
will serve as an open resource for studying commonsense, and an example of the advantage of
explicitly modeling commonsense knowledge in
contrast to general task modeling alone.
