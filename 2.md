Evaluation of Natural Language Processing Components.


The performance of each individual component in the
natural language processing pipeline can place an effective
upper bound on the ability to accurately extract information.
Imperfect performance in earlier stages carries through the
pipeline and can degrade the performance of each subsequent
stage. For example, incorrect POS tags can have a direct
negative impact on both the recognition of chemical entities
and the parsing of a sentence. Likewise, missing or incorrectly
recognized chemical entity names can invalidate the extraction
of all associated spectroscopic data and properties.


Therefore, it is important to quantify the performance of
each component to identify the greatest barriers to improved
performance of the overall system.




Chemical Entity Mentions.


To facilitate comparison with
other text mining tools, recognition of individual chemical
mentions was evaluated. This evaluation was performed using
the CHEMDNER corpus.33 This consists of 3000 abstracts
from across the chemistry domain that have been manually
annotated with 25 351 chemical entity mentions. Results were
calculated using the bc-evaluate tool provided by the
CHEMDNER organizers.


Table 8 shows the precision, recall and F-score for the
individual CRF, dictionary and regular expression components
of the chemical entity recognition system, as well as for the
overall combined system. The overall combined F-score of
87.8% exceeds the scores achieved by all the tools that officially
entered the CHEMDNER chemical names extraction challenge.
32 The two best entries were tmChem by Leaman et al.,37
which achieved an F-score of 87.39%, and a system by Lu et
al.,38 which achieved an F-score of 87.11%. Lu et al. have since
published an alternative version of their system that achieved an
F-score of 88.06%, which outperforms ChemDataExtractor on
this statistic by 0.3%.


The CRF recognizer with word cluster features is the best
performing individual component, with an F-score of 84.9%.
While the dictionary recognizer has similar precision to the
CRF, it has inferior recall, primarily caused by poor recognition
of systematic names and chemical formulas. This weakness is
typical of dictionary-based methods, where each chemical name
must be present in the dictionary for it to be successfully
recognized.







The regular expression recognizer is only designed to
recognize a limited set of chemical identifier patterns, such as
database registry numbers and chemical formulas, and therefore
has poor recall of just 11.0% when applied on its own.
However, these types of chemical identifiers can pose the
greatest difficulty for the CRF and dictionary methods, and
therefore the regular expression component still makes a
worthwhile contribution to the overall combined system.












POS Tagging.


POS tagging performance was evaluated
through the use of two different corpora that have been
manually annotated with POS tags: The Wall Street Journal
(WSJ) corpus,28 which consists of 1 million words from 1989
Wall Street Journal news articles, and the GENIA corpus,29
which consists of 2000 MEDLINE abstracts that cover the
biomedical domain. The standard WSJ splitting convention was
used, with sections 0−18 for training, 19−21 for development,
and 22−24 for evaluation. The first 90% of the GENIA corpus
was used for training, and the remaining 10% for evaluation,
matching the split used by Tsuruoka et al.4 in developing a
biomedical POS tagger.




Table 9 presents the POS tagging accuracy of different
training configurations on the WSJ and GENIA evaluation
corpora. Supervised training was performed using the WSJ and
GENIA training corpora individually, and also both combined.
The effect of adding unsupervised features from word clusters
was also evaluated on each of these three configurations.


Taggers trained individually on either the WSJ or the GENIA
corpus achieved the best performance when evaluated on that
same corpus but afforded the poorest performance when
evaluated on the opposite corpus. The tagger trained on the
WSJ training corpus achieved an accuracy of 97.23% on the
WSJ evaluation corpus, which falls to 84.15% on the GENIA
evaluation corpus. Likewise, the tagger trained on the GENIA
training corpus achieved an accuracy of 98.62% on the GENIA
evaluation corpus, which falls to 81.19% on the WSJ evaluation
corpus.



The tagger trained on the combined WSJ and GENIA
corpora achieves good accuracy on both evaluation corpora,
with 97.08% on the WSJ evaluation corpus and 98.34% on the
GENIA evaluation corpus. This matches the observations of
Tsuruoka et al., indicating that using the combined newspaper
and biomedical training sets extends coverage over both and
has little negative impact compared to the specialized training
for a specific domain.





The addition of word cluster features has a positive effect in
all cases, but this is most significant in the cases where there is a
mismatch between the training corpus and the evaluation
corpus. The accuracy of the WSJ-trained tagger on the GENIA
corpus rises from 83.50% to 84.15%, and the accuracy of the
GENIA-trained tagger on the WSJ corpus rises from 78.88% to
81.19%. This suggests that unsupervised word cluster features
are capable of broadening the coverage of a POS tagger outside
the domain of its supervised training and, therefore, should lead
to improved performance across the wider chemistry domain
for the tagger trained on the combined WSJ and GENIA
corpus.
