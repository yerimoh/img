We introduce a simple yet efficient and universally applicable economical pipeline to dynamically
decide the LLMs in reasoning tasks, so as to save the token costs. Our approach based on checking
the answer consistency of the weaker LLM is novel and effective. Our discoveries emphasize that
leveraging prompts with a mixture of thought representations in weaker LLM achieves the best
performance as it introduces diverse answers. Compared with fully employing the stronger LLM,
our pipeline requires approximately 40% of expenses to achieve a comparable result. Future works
are listed in Appendix K.
