# SUPER-NATURALINSTRUCTIONS:  Generalization via Declarative Instructions on 1600+ NLP Tasks


# Abstract
**ëª©ì :**    
NLP ëª¨ë¸ì„ instructionsê³¼ í•¨ê»˜ ì œê³µë  ë•Œ **_ë‹¤ì–‘í•œ_ unseen tasks**ìœ¼ë¡œ ì¼ë°˜í™”          

**ë°©ë²•:** 
* 1,616ê°œì˜ ë‹¤ì–‘í•œ NLP ì‘ì—…ê³¼ ì „ë¬¸ê°€ê°€ ì‘ì„±í•œ ì§€ì¹¨ì˜ ë²¤ì¹˜ë§ˆí¬ì¸ SUPER-NATURALINSTRUCTIONSì„ ì†Œê°œ.      
ìš°ë¦¬ì˜ ì»¬ë ‰ì…˜ì€  classification, extraction, infill
ing, sequence tagging, text rewriting, and text
 composition.ì„ í¬í•¨í•˜ì§€ë§Œ ì´ì— êµ­í•œë˜ì§€ ì•ŠëŠ” 76ê°œì˜ ê°œë³„ task ìœ í˜•ì„ ë‹¤ë£¸.      
* ì´ë ‡ê²Œ í¬ê³  ë‹¤ì–‘í•œ task ëª¨ìŒì„ í†µí•´ instructionsê³¼ì— ë”°ë¼ cross-task generalizationë¥¼ ì—„ê²©í•˜ê²Œ ë²¤ì¹˜ë§ˆí‚¹í•  ìˆ˜ ìˆìŒ    
 ì¦‰, ëª¨ë¸ì´  subset of tasksì— ëŒ€í•œ instructionsì„ ë”°ë¥´ë„ë¡ trainingí•˜ê³ , ë‚˜ë¨¸ì§€ unseen taskì— ëŒ€í•œ ì§€ì¹¨ì„ í‰ê°€í•¨      
* Tk-INSTRUCT build    
ë‹¤ì–‘í•œ incontext instructions(ì¼ë°˜ ì–¸ì–´ ì‘ì—… ì •ì˜ ë˜ëŠ” k-shot ì˜ˆì œ)ì„ ë”°ë¥´ë„ë¡ trainëœ  transformer      

**ê²°ê³¼:**     
* ìš°ë¦¬ì˜ ì‹¤í—˜ì— ë”°ë¥´ë©´ **Tk-INSTRUCTëŠ” í¬ê¸°ê°€ ë‹¤ì†Œ ì‘ìŒì—ë„ ë¶ˆêµ¬**í•˜ê³ ,   
 Instruct GPTì™€ ê°™ì€ ê¸°ì¡´ instruction-following ëª¨ë¸ì„ **ë²¤ì¹˜ë§ˆí¬ì—ì„œ 9% ì´ìƒ ëŠ¥ê°€**     
 
ìš°ë¦¬ëŠ” ê´€ì°°ëœ ì‘ì—… ìˆ˜, ì‘ì—…ë‹¹ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜, ëª¨ë¸ í¬ê¸°ì™€ ê°™ì€ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ë§ ë§¤ê°œ ë³€ìˆ˜ì˜ í•¨ìˆ˜ë¡œì„œ ì¼ë°˜í™”ë¥¼ ì¶”ê°€ë¡œ ë¶„ì„.   
ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ë°ì´í„° ì„¸íŠ¸ì™€ ëª¨ë¸ì´ ë” ë²”ìš©ì ì¸ NLP ëª¨ë¸ì„ í–¥í•œ ë¯¸ë˜ì˜ ë°œì „ì„ ì´‰ì§„í•˜ê¸°ë¥¼ ë°”ë€ë‹¤.       


---
---
 
 
 # 1 Introduction

**[ê¸°ì¡´ ë¬¸ì œ]**            
* íŠ¹íˆ ì£¼ìš” ëª¨ë¸ ë’¤ì— ìˆëŠ” **ê¸°ì—…ì—ì„œ ê³µê°œí•œ ë°ì´í„°ê°€ ì œí•œì **ì´ì–´ì„œ supervised dataì˜ ì—­í• ì€ ì—¬ì „íˆ ë¯¸ì§„í•œ ìƒíƒœë¡œ ë‚¨ì•„ ìˆë‹¤.     
* ê²Œë‹¤ê°€, ì—°êµ¬ ì»¤ë®¤ë‹ˆí‹°ê°€ ì´ëŸ¬í•œ **ê±°ëŒ€í•œ ëª¨ë¸ì„ í™•ì¥í•˜ê³  ì¬êµìœ¡í•˜ëŠ” ê²ƒì€ ê±°ì˜ ë¶ˆê°€ëŠ¥**í•©ë‹ˆë‹¤.      

â¡ ì´ ë‘ ê°€ì§€ ê³¼ì œë¥¼ í•´ê²°í•˜ë ¤ë©´, unseen tasksìœ¼ë¡œ ì¼ë°˜í™”í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ê³  í‰ê°€í•˜ê¸° ìœ„í•´ **ê´‘ë²”ìœ„í•œ NLP ì‘ì—…ì˜ large-scale public benchmarksì™€ instructionsì„ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì•¼ í•¨**          


**[ë³¸ ë…¼ë¬¸ì˜ í•´ê²°]**         
* **í•´ê²° 1)** ë³¸ ë…¼ë¬¸ì€, instructionsê³¼ í•¨ê»˜ ë‹¤ì–‘í•œ NLP ì‘ì—…ìœ¼ë¡œ êµ¬ì„±ëœ <span style="background-color:#FFE6E6">**meta-dataset(SUP-NATINST)ë¥¼ êµ¬ì„±**</span>            
* **í•´ê²° 2)** instructionsì´ ì£¼ì–´ì§„ <span style="background-color:#FFE6E6">new taskì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” **ëª¨ë¸(Tk-INSTRUCT)**</span>ì„ trainí•˜ì—¬ **Instruct GPT(16ë°° ë” ë§ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©)ë¥¼ ëŠ¥ê°€**í•¨.                

**[í•´ê²° 1) dataset: SUPER-NATURALINSTRUCTIONS (SUP-NATINST for short)]**       
* ìš°ë¦¬ì˜ ë°ì´í„° ì„¸íŠ¸ì¸ SUP-NATINSTëŠ” 1,616ê°œì˜ NLP ì‘ì—…ê³¼ í•´ë‹¹ ìì—°ì–´ ëª…ë ¹ì˜ ëŒ€ê·œëª¨ ë²¤ì¹˜ë§ˆí¬ì„.     
* 55ê°œ ì–¸ì–´ì— ê±¸ì¹œ 76ê°œì˜ ê´‘ë²”ìœ„í•œ ì‘ì—… ìœ í˜•ê³¼ ê°™ì€ ë‹¤ì–‘í•œ taskë¥¼ ì œê³µ        
* ê° taskëŠ” **ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ task ì¶œë ¥ì— ë§¤í•‘í•˜ê¸° ìœ„í•œ task ì •ì˜**ì™€ ì›í•˜ëŠ” ë˜ëŠ” **ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ì˜ˆì œë¡œ êµ¬ì„±ëœ ëª…ë ¹**ê³¼ ìŒì„ ì´ë£¸ (Figure 1)       
* ì´ëŸ¬í•œ taskì™€ instructions 88ëª…ì˜ NLP ì‹¤ë¬´ìê°€ ê³µê°œ ìš”ì²­ì— ë”°ë¼ ì œê³µí•©ë‹ˆë‹¤.     
ì´ëŸ¬í•œ ê¸°ì—¬ëŠ” í’ˆì§ˆì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ì°¨ë¡€ì˜ ë™ë£Œ ê²€í†  ë° í¬ë¼ìš°ë“œì†Œì‹± í”¼ë“œë°±ì„ ê±°ì¹œ í›„ í†µí•©ë¨.      
* ì´ë ‡ê²Œ ë‹¤ì–‘í•˜ê³  ëŒ€ê·œëª¨ì˜ ë°ì´í„°ë¥¼ ë³´ìœ í•˜ë©´ taskë¥¼ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‹ ì¤‘í•˜ê²Œ ë‚˜ëˆ„ê³  ìµœì²¨ë‹¨ ë°©ë²•ì´ ì´ë“¤ì—ê²Œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬ ê°€ëŠ¥      
* Table 1ê³¼ ê·¸ë¦¼ 2ëŠ” ê´€ë ¨ ë²¤ì¹˜ë§ˆí¬ì™€ ë¹„êµí•˜ì—¬ SUP-NATINSTì˜ ì†ì„±ì„ ê°•ì¡°í•˜ë©° ë²¤ì¹˜ë§ˆí¬ì˜ ì‘ì—… ë° êµìœ¡ ìœ í˜•ì˜ ë‹¤ì–‘ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.    


**Figure 1: An example task from SUP-NATINST**     
<img width="217" alt="image" src="https://github.com/yerimoh/img/assets/76824611/4cd3f109-f796-4981-be06-46b0cef76081">

**Table 1: SUP-NATINSTë¥¼ fieldì—ì„œ ì£¼ëª©í•  ë§Œí•œ ëª‡ ê°€ì§€ ë°ì´í„°ì…‹ê³¼ ë¹„êµ**.             
<img width="416" alt="image" src="https://github.com/yerimoh/img/assets/76824611/9f885db3-a4a5-41cd-b3b9-91975f09081c">
* ìš°ë¦¬ëŠ” ì›ë³¸ ë…¼ë¬¸ì—ì„œ ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ì˜ ì‘ì—… ìˆ˜, instructions ë° task typesì„ ì–»ìŒ     
*  "â€“" ëŠ” ì ìš©í•  ìˆ˜ ì—†ê±°ë‚˜ ì•Œ ìˆ˜ ì—†ìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.     
*  task typeì„ ë¶„ë¥˜í•˜ëŠ” í‘œì¤€ì€ ë°ì´í„° ì„¸íŠ¸ë§ˆë‹¤ ë‹¤ë¦„(Figure 2 ì°¸ì¡°)      
*  PROMPTSOURCEëŠ” ëª¨ë“  taskì— ëŒ€í•œ task type ì£¼ì„ì„ ì œê³µí•˜ì§€ ì•Šìœ¼ë©°, ëŒ€ì‹  T0 êµìœ¡ì„ ìœ„í•´ ì£¼ì„ì´ ë‹¬ë¦° 13ê°œì˜ task typeë§Œ ë³´ê³ í•¨ 

**Figure 2: Compared to other datasets**        
<img width="427" alt="image" src="https://github.com/yerimoh/img/assets/76824611/22d563d8-e4c7-43ff-b88e-4d94542ad7c8">
* ë‹¤ë¥¸ ë°ì´í„°ì…‹ì— ë¹„í•´ SUP-NATINSTëŠ” ë” ë‹¤ì–‘í•œ task typesì„ ì§€ì›í•¨      
* InstructGPTì˜ task typesì˜ ë§¤ìš° ê±°ì¹œ(coarse) ë¶„ë¥˜ë¥¼ í•˜ëŠ” ê±¸ë¡œ ë³´ì„    
* ë²„ë¸” í¬ê¸°ëŠ” log scaleì—ì„œ ê° ìœ í˜•ì˜ íƒœìŠ¤í¬ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„        



**[í•´ê²° 2) model: Tk-INSTRUCT]**
* ìš°ë¦¬ì˜ ëª¨ë¸ì¸ Tk-INSTRUCTëŠ” in-context instructions (task definition ë˜ëŠ” _k-shot_ ì˜ˆì œ)ì´ ì£¼ì–´ì§„ task inputì„ ë³€í™˜í•˜ê¸° ìœ„í•œ generative ëª¨ë¸ì„.      
* T5 ëª¨ë¸(Raffel et al., 2020)ì˜ multi-task trainingì— ì˜í•´ training ì„¸íŠ¸ì˜ ëª¨ë“  ì‘ì—… ì§€ì¹¨ì— ê±¸ì³ êµ¬ì¶•ë˜ë©°,    
test setì—ì„œ unseen taskì— ëŒ€í•´ í‰ê°€ë¨       
* í¥ë¯¸ë¡­ê²Œë„, 11B ë§¤ê°œ ë³€ìˆ˜ Tk-INSTRUCTëŠ” 119ê°œì˜ unseen English tasksì—ì„œ í‰ê°€ë  ë•Œ,     
**175B-parameter InstructGPT ëª¨ë¸ì„ 9.9 ROUGE-L pointsë§Œí¼ ëŠ¥ê°€**í•  ìˆ˜ ìˆìœ¼ë©°,         
multilingual variant mTk-INSTRUCTëŠ” 35ê°œì˜ ì˜ì–´ê°€ ì•„ë‹Œ ì‘ì—…ì—ì„œ **13.3 pointsë§Œí¼ InstructGPTë¥¼ ëŠ¥ê°€**í•¨      
* human evaluationì— ë”°ë¥´ë©´, Tk-INSTRUCTëŠ” testing instancesì˜ 77%(Â§6.2)ì— ëŒ€í•œ ì‹¤ì œì™€ ë§ëŠ” ìƒì„±í•˜ì—¬ **unseen tasksì— ëŒ€í•œ ê°•ë ¥í•œ ì¼ë°˜í™”**ë¥¼ í™•ì¸í•œë‹¤.        



**[understand the important factors for this generalization]**        
* TkINSTRUCTì˜ ê°•ë ¥í•œ empirical ì„±ëŠ¥ì€ generalizable NLP ëª¨ë¸ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ìš©ì´í•˜ê²Œ í•˜ê¸° ìœ„í•´ **SUP-NATINSTì™€ ê°™ì€ ì´ˆëŒ€í˜• ë©”íƒ€ ë°ì´í„° ì„¸íŠ¸ì˜ ì¤‘ìš”ì„±ì„ í™•ì¸**í•¨      
* ìš°ë¦¬ëŠ” ì´ generalizationì˜ ì¤‘ìš”í•œ ìš”ì†Œë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ê´‘ë²”ìœ„í•œ ë¶„ì„ì„ ìˆ˜í–‰í•¨(Â§7)      
* ìš°ë¦¬ì˜ ë¶„ì„ì€ <span style="background-color:#fff5b1">**training taskì˜ ë‹¤ì–‘ì„±**ê³¼ **model sizeë¥¼ í™•ì¥**í•˜ëŠ” ê²ƒì´ **unseen tasksì— ëŒ€í•œ ê°•ë ¥í•œ generalizationì— ì¤‘ìš”**</span>í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ     
* ë§ˆì§€ë§‰ìœ¼ë¡œ ì„±ëŠ¥ ìƒí•œì„ ì¶”ì •í•˜ì—¬ ì¶”ê°€ ê°œì„ ì˜ ì—¬ì§€ë¥¼ ì œì‹œí•¨      


------
-----

# 2 SUPER-NATURALINSTRUCTIONS
   

**[Instruction schema]**      
* ëª¨ë“  task instructionì€ ë‹¤ìŒ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ëœ  uniform schema (see Fig. 1)ë¥¼ ë”°ë¥¸ë‹¤.         
   * **DEFINITION**     
   ì£¼ì–´ì§„ taskë¥¼ ìì—°ì–´ë¡œ ì •ì˜í•¨    
   ì´ê²ƒì€ ì…ë ¥ í…ìŠ¤íŠ¸(ì˜ˆ: ë¬¸ì¥ ë˜ëŠ” ë¬¸ì„œ)ê°€ ì¶œë ¥ í…ìŠ¤íŠ¸ì— ë§¤í•‘ë˜ëŠ” ë°©ì‹ì— ëŒ€í•œ  complete definitionì„   
   * **POSITIVE EXAMPLES**      
   ê¸ì •ì ì¸ ì˜ˆëŠ” ê°ê°ì˜ ê°„ë‹¨í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì…ë ¥ ë° ì˜¬ë°”ë¥¸ ì¶œë ¥ì˜ ìƒ˜í”Œì„          
   * **NEGATIVE EXAMPLES**        
   ê°ê°ì˜ ê°„ë‹¨í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì…ë ¥ ìƒ˜í”Œê³¼ incorrect/invalid ì¶œë ¥ì´ ìˆìŒ     

---

**[Task instances]**     
* ê° taskì— ëŒ€í•œ instructionsì´ ì£¼ì–´ì§€ë©´ ëª¨ë¸ì´ í•´ë‹¹ taskì˜ instancesë¥¼ í•´ê²°í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë¨     
* í†µí•©ëœ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  taskì˜ instancesë¥¼ êµ¬ì„±í•¨       
* ê° instances textual inputê³¼ f acceptable textual outputs ëª©ë¡ìœ¼ë¡œ êµ¬ì„±ë¨     
* ì‘ì—… ê°„ ì¸ìŠ¤í„´ìŠ¤ì˜ ë¶ˆê· í˜•ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ê° ì‘ì—…ì˜ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ 6.5Kë¡œ ì œí•œí•¨          

---

**[Benchmark collection]**   
* ë²¤ì¹˜ë§ˆí¬ëŠ” GitHub.3ì— ëŒ€í•œ ëŒ€ê·œëª¨ ì»¤ë®¤ë‹ˆí‹° ë…¸ë ¥ì„ í†µí•´ ìˆ˜ì§‘ë¨    
* taskëŠ” ê³µê°œ ì´ˆëŒ€ì— ì‘ë‹µí•œ NLP ì‹¤ë¬´ìë“¤ì— ì˜í•´ ìˆ˜ì§‘ ë° ê¸°ì—¬ë¨      
  * (a) ê¸°ì¡´ì˜ ê³µê°œ NLP ë°ì´í„° ì„¸íŠ¸      
  * (b) í¬ë¼ìš°ë“œì†Œì‹± ì‹¤í—˜ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì¤‘ê°„ ì£¼ì„ (ì˜ˆ: QA ë°ì´í„° ì„¸íŠ¸ë¥¼ í¬ë¼ìš°ë“œì†Œì‹±í•˜ëŠ” ë™ì•ˆ ì§ˆë¬¸ì„ ë°”ê¾¸ì–´ í‘œí˜„í•˜ê±°ë‚˜ í’ˆì§ˆì„ í‰ê°€í•¨)      
  * (c) ë¬¸ì¥ìœ¼ë¡œ ì¸ê°„ì—ê²Œ ì „ë‹¬ë  ìˆ˜ ìˆëŠ” synthetic tasks (ì˜ˆ: ìˆ«ì ë¹„êµ, ê°€ì¥ ê¸´ íŒ”ì¸ë“œë¡¬ í•˜ìœ„ ë¬¸ìì—´ ì°¾ê¸°, ë“±)    

---

**[Quality control]**    
* ì´ community-contributed ë°ì´í„°ì˜ í’ˆì§ˆ ê´€ë¦¬ëŠ” ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ìˆ˜í–‰ë¨.           
* ë‹¨ê³„    
**(1)** ì œì•ˆëœ ì‘ì—…ì˜ GitHub í’€ ìš”ì²­ì„ ìƒì„±í•œ í›„ ì¦‰ì‹œ automatic testë¥¼ ê±°ì¹¨       
ì´ í”„ë¡œì„¸ìŠ¤ëŠ” ë„ì…ëœ íŒŒì¼ì— ì˜ˆìƒ í•„ë“œê°€ í¬í•¨ë˜ì–´ ìˆê³  ì›í•˜ëŠ” ì†ì„±(ì˜ˆ: ì¤‘ë³µ ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ, ì¶œë ¥ ë ˆì´ë¸”ì´ í¬ê²Œ ë¶ˆê· í˜•í•˜ì§€ ì•ŠìŒ ë“±)ì„ ì¤€ìˆ˜í•˜ëŠ”ì§€ í™•ì¸í•¨    
**(2)** ì œì•ˆëœ ì‘ì—…ì€ 1-2ëª…ì˜ ë‹¤ë¥¸ ì „ë¬¸ê°€ ê¸°ì—¬ìì— ì˜í•´ ë™ë£Œ ê²€í† ë˜ì–´ êµìœ¡ ë‚´ìš©ì˜ ëª…í™•ì„±ê³¼ ì¶©ë¶„ì„±ì„ ë³´ì¥      
**(3)** ë§ˆì§€ë§‰ìœ¼ë¡œ, ì˜¤íƒ€, ëª…í™•ì„± ë˜ëŠ” ê¸°íƒ€ ë¬¸ì œ(ìì„¸í•œ ë‚´ìš©ì€ Â§A)ì™€ ê°™ì€ ì œê³µëœ ì§€ì¹¨ì˜ í’ˆì§ˆì— ëŒ€í•œ í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ ì¶”ê°€ëœ ì‘ì—…ì„ í¬ë¼ìš°ë“œ ì›Œì»¤ì—ê²Œ ì œì‹œ

---

**[Diversity of tasks]**     
* SUPNATINSTë¥¼ ìœ„í•œ ì‘ì—… ìˆ˜ì§‘ì€ ë‹¤ì–‘í•œ ìì—°ì–´ ì´í•´ ì‘ì—…, ë„ë©”ì¸ ë° ì–¸ì–´ë¥¼ í¬í•¨í•˜ë„ë¡ ì„¸ì‹¬í•˜ê²Œ ìˆ˜ì§‘ë¨     
* ì´ëŸ¬í•œ ë‹¤ì–‘ì„±ì„ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ taskë¥¼ ì„¸ ê°€ì§€ ì°¨ì›ìœ¼ë¡œ í¬ê´„ì ìœ¼ë¡œ ë¶„ë¥˜í•¨:     
   * **TASK TYPE**    
   ì¸ìŠ¤í„´ìŠ¤ ì…ë ¥ì—ì„œ ì¶œë ¥(ì˜ˆ: ì§ˆë¬¸ ë‹µë³€, ë¶„ë¥˜ ë“±)ì— ì´ë¥´ëŠ” ë§¤í•‘ì˜ íŠ¹ì„±     
   * **LANGUAGE**      
   instancesì˜ ì–¸ì–´ë¥¼ ë‚˜íƒ€ëƒ„
   * **DOMAIN**        
   ì‘ì—… í…ìŠ¤íŠ¸ê°€ ì†í•˜ëŠ” ë„ë©”ì¸(ì˜ˆ: ì •ì¹˜, ì˜í•™, ëŒ€í™” ë“±)ì„ ë‚˜íƒ€ëƒ„    

ì´ëŸ¬í•œ ì„œë¡œ ë‹¤ë¥¸ categorization ì¸¡ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ **ì¼ë°˜í™”ì˜ ë‹¤ì–‘í•œ ì˜ë¯¸ë¥¼ ì—°êµ¬** ê°€ëŠ¥    

----

**[Statistics]**        
* Table 2ëŠ” ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ë‹¤ì–‘í•œ í†µê³„ë¥¼ ë³´ì—¬ì¤Œ.        
* ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ì´ 1616ê°œì˜ taskê³¼ 5Mê°œì˜ instancesê°€ í¬í•¨ë¨        
<img width="221" alt="image" src="https://github.com/yerimoh/img/assets/76824611/a95c3055-6319-4330-b8f4-38237613d277">


----
----

# 3. Tk-INSTRUCT: Learning to Follow Instructions at Scale

**[Defining Generalization to Unseen Tasks]**          
* ê° task $$t$$ëŠ” natural language instruction $$I_t$$ì„ í†µí•´ ì •ì˜ë¨       
* ê° taskì—ëŠ” ì¼ë ¨ì˜ input/output instances($$X_t$$, $$Y_t$$)ê°€ ì¡´ì¬     
* **ëª©í‘œ:**    
ì…ë ¥ $$x$$ì™€ task instruction $$I_t: M(I_t, x) = y(x, y) âˆˆ(X_t, Y_t)$$ì— ëŒ€í•´ $$M$$ ëª¨ë¸ì´ ì¶œë ¥ $$y$$ë¥¼ ìƒì„±í•´ì•¼ í•¨.        
* **í‰ê°€:**    
íŠ¹íˆ not observed(ì¦‰, í•´ë‹¹ instancesê°€ M í›ˆë ¨ì— ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)ì— ëŒ€í•´ ëª¨ë¸ $$M$$ì„ í‰ê°€í•˜ê³ ì í•¨     
* inference ì‹œê°„ì— task í•™ìŠµí•˜ê¸° ìœ„í•œ ìœ ì¼í•œ source of signalëŠ” ì‘ì—…ì˜ definition ë° d demonstration examplesë¥¼ í¬í•¨í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë‚´ instructions($$I_t$$)ì„     

----

**[Tk-INSTRUCT]**      
* ìš°ë¦¬ëŠ” <span style="color:#ffd33d">**SUP-NATINSTì—ì„œ meta-trainedì„ ë°›ì€ ëª¨ë¸**ì¸ Tk-INSTRUCTë¥¼ ì†Œê°œ</span>í•¨     
* ì´ ëª¨ë¸ì€ **context ë‚´ instructionì— ë”°ë¼ taskë¥¼ í•´ê²°í•¨**       
* SUP-NATINSTì˜ <span style="color:#ffd33d">**ë‹¤ì–‘í•œ task**ë¡œ ì¸í•´ **ì´ì „ë³´ë‹¤ ë” í° ê·œëª¨ë¡œ ì´ multi-task meta-trainingì„ ìˆ˜í–‰ ê°€ëŠ¥**</span>       
* [T5 ëª¨ë¸](https://yerimoh.github.io/LAN24/)ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í—˜ ë° ë¶„ì„ì„ ìˆ˜í–‰      
* ê° ëª…ë ¹ì–´ëŠ” (Â§2)ì— ì„¤ëª…ëœ ëŒ€ë¡œ ì—¬ëŸ¬ ìš”ì†Œë¡œ êµ¬ì„±ë˜ë¯€ë¡œ, ì´ëŸ¬í•œ ìš”ì†Œë¥¼ í…ìŠ¤íŠ¸ í˜•ì‹ì— ë§¤í•‘í•˜ê³  ì…ë ¥ ì¸ìŠ¤í„´ìŠ¤ ì•ì— ì¶”ê°€í•¨.     
* ì•„ë˜ ì „ì²´ instructionì„ ì¸ì½”ë”©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤Œ     
<img width="205" alt="image" src="https://github.com/yerimoh/img/assets/76824611/d77e9c2d-9de5-441a-a4a0-35bb5aba52fd">
* ìš°ë¦¬ëŠ” (Â§ 6.2 Instructing with Different Elements)ì—ì„œ ì´ëŸ¬í•œ instructionë“¤ì˜ ë‹¤ì–‘í•œ ì¡°í•©ì„ ì—°êµ¬í•¨       
* ë‹¬ë¦¬ ëª…ì‹œë˜ì§€ ì•ŠëŠ” í•œ, ê¸°ë³¸ì ìœ¼ë¡œ ê°€ì¥ íš¨ê³¼ì ì¸ instruction ìš”ì†Œ(ì¦‰, task definitionì™€ ë‘ ê°€ì§€ positive example)ë¥¼ ì‚¬ìš©      
----
----


# 4 Benchmarking Cross-Task
Generalization with SUP-NATINST Here we provide our recommended recipe for benchmarking generalization via SUP-NATINST.

SUP-NATINSTë¥¼ í†µí•œ ì¼ë°˜í™” SUP-NATINSTë¥¼ í†µí•œ ì¼ë°˜í™” ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•œ ê¶Œì¥ ë ˆì‹œí”¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## 5.1 Evaluation Setup
**[An Evaluation Split of Unseen Tasks]**      
* SUP-NATINSTì˜ ëŒ€ê·œëª¨ task ëª¨ìŒì„ **two subsetsìœ¼ë¡œ ë‚˜ëˆ”**:    
  * **evaluationìš© task**   
  154ê°œ ì‘ì—…ì„ ë‚˜íƒ€ë‚´ëŠ” 12ê°œ ë²”ì£¼ì˜ manuallyselected ì»¬ë ‰ì…˜ì„ fix   
  * **supervisionìš© task**            


    
<details>
<summary>ğŸ“œ ëŒ€í‘œì ì¸ taskì— ëŒ€í•œ ì˜ˆì œì™€ í•¨ê»˜ evaluation task ë³´</summary>
<div markdown="1">

<img width="307" alt="image" src="https://github.com/yerimoh/img/assets/76824611/db62316a-6170-482b-8859-812d8d4a73a0">
 
 </div>
</details>  




**[Divided Tracks for English and X-lignual Tasks]**      
* SUP-NATINSTëŠ” ì—¬ëŸ¬ ì–¸ì–´ì— ê±¸ì¹œ taskë¡œ êµ¬ì„±ë˜ì–´ ì˜ì–´ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ì–¸ì–´ë¡œë„ unseen tasksì— ëŒ€í•œ ëª¨ë¸ì˜ generalizationì„ í‰ê°€ ê°€ëŠ¥     
* ë”°ë¼ì„œ evaluation tasksì„ two tracksìœ¼ë¡œ ë‚˜ëˆ”     
  * **English cross-task generalization (119 tasks)**     
  * **cross-lingual cross-task generalization (35 tasks)**      
  ì¦‰, ë‹¤ë¥¸ ì–¸ì–´ë¡œ unseen taskì— ëŒ€í•œ ì¼ë°˜í™”          
  



**[Evaluation Metrics]**     
* ROUGE-L(Lin, 2004)ì„ ì±„íƒ      
ì´ëŠ” ê´‘ë²”ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—…ì— ì ìš©í•  ìˆ˜ ìˆëŠ” soft string overlap metricë‹ˆë‹¤.     
* human evaluationë„ ì‚¬ìš©

----
---

# 5. Experimental Results   

<img width="288" alt="image" src="https://github.com/yerimoh/img/assets/76824611/0d5f329b-f356-46de-972c-4027e38695e6">
* Instruction-tuning enables **stronger generalization** to unseen tasks      
* Our **Tk-INSTRUCT outperforms** InstructGPT      
* There is a **sizable gap for improvement**     


----
----


# 6. Conclusion
We construct a large-scale benchmark consisting
of a diverse set of NLP tasks and their instructions.
This benchmark can serve as a rich playground for
training or evaluation of models that can generalize
to unseen tasks by following instructions. Furthermore, we train Tk-INSTRUCT using this data, and
demonstrate its capability to perform unseen tasks
to a surprising extent. We provide extensive analysis to understand the important factors for such
generalization. We hope our data and model will facilitate future work towards more general-purpose
models.


----
----

# 7. Limitations
While the presented data offers a notable variety
(e.g., diverse task types), its underlying distributions suffer from skews which should be addressed
in future work (see Appendix F). On language diversity, the proposed benchmark is biased toward
English. On output diversity, the collected tasks
are generally still skewed to short responses, which
might reflect the distribution of the available tasks
in the field. This under-representation of the longtail of tasks poses a challenge for building generalpurpose models in the future. We hope future work
addresses such distributional imbalances. Moreover, we see natural extensions of the instructionfollowing setup here in the context of other modalities such as vision or speech.

Automatic evaluation of modelsâ€™ performance
is another challenge, considering the diverse set of
tasks in our benchmark, and many of them being
open-ended generation tasks. We use ROUGE-L as
an aggregated metric in this paper and find it as a
good proxy for the overall performance of the mod
els, aligning well with human evaluation. However,
there are specific tasks for which ROUGE-L might
not serve as an effective proxy of quality (such
as rewriting tasks or error correction tasks where
copying the input can result in a high ROUGE-L
score). We hope these issues will be addressed
with the development of more powerful evaluation
metrics for text generation.

In terms of computing power, we have experimented with models that were accessible to us and
have made the resulting models publicly available.
We also acknowledge that there are larger models
that we were not able to train due to the limitations
of our computational budget.
